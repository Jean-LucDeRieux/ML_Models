{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to be install\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, parent, child, label):\n",
    "        self.parent = parent\n",
    "        self.child = child\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softplus(x):\n",
    "    return np.log(np.exp(x) + 1)\n",
    "\n",
    "def cross_entropy(output, label):\n",
    "    epsilon = 1e-7\n",
    "    output = np.clip(output, epsilon, 1 - epsilon)\n",
    "    return -np.sum(label * np.log(output) + (1 - label) * np.log(1 - output))\n",
    "\n",
    "def mse(output, label):\n",
    "    return 0.5 * np.sum((output - label) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_input, num_hidden, num_output, act_func, loss_func, bias):\n",
    "        self.act_func = act_func\n",
    "        self.loss_func = loss_func\n",
    "        self.bias = bias\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights = [np.random.uniform(-1, 1, (num_input, num_hidden[0]))]\n",
    "        self.biases = [np.random.uniform(-1, 1, (1, num_hidden[0]))]\n",
    "        for i in range(1, len(num_hidden)):\n",
    "            self.weights.append(np.random.uniform(-1, 1, (num_hidden[i-1], num_hidden[i])))\n",
    "            self.biases.append(np.random.uniform(-1, 1, (1, num_hidden[i])))\n",
    "        self.weights.append(np.random.uniform(-1, 1, (num_hidden[-1], num_output)))\n",
    "        self.biases.append(np.random.uniform(-1, 1, (1, num_output)))\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        activations = self.forward_prop(inputs)\n",
    "        output = activations[-1]\n",
    "        return output\n",
    "\n",
    "    def forward_prop(self, inputs):\n",
    "        activations = [inputs]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            inputs = np.dot(inputs, w) + b\n",
    "            if self.act_func =='relu':\n",
    "                inputs = np.clip(inputs, -10, 10)\n",
    "                inputs = np.maximum(0, inputs)\n",
    "            elif self.act_func =='sigmoid':\n",
    "                inputs = 1 / (1 + np.exp(-inputs))\n",
    "            elif self.act_func =='softplus':\n",
    "                inputs = np.log(np.exp(np.clip(inputs, -10, 10)) + 1)\n",
    "            activations.append(inputs)\n",
    "        return activations\n",
    "\n",
    "    def back_prop(self, inputs, labels):\n",
    "        activations = self.forward_prop(inputs)\n",
    "        output = activations[-1]\n",
    "\n",
    "        # Calculate loss\n",
    "        if self.loss_func == 'CrossEntropy':\n",
    "            loss = cross_entropy(output, labels)\n",
    "        elif self.loss_func =='mse':\n",
    "            loss = mse(output, labels)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss function. It should be 'cross_entropy' or'mse'.\")\n",
    "\n",
    "        # Backpropagation\n",
    "        d_output = output - labels if self.loss_func == 'CrossEntropy' else 2 * (output - labels)\n",
    "        d_weights = []\n",
    "        d_biases = []\n",
    "        for i in range(len(self.weights) - 1, -1, -1):\n",
    "            if self.act_func =='sigmoid':\n",
    "                d_output *= activations[i+1] * (1 - activations[i+1])\n",
    "            elif self.act_func =='relu':\n",
    "                d_output *= (activations[i+1] > 0).astype(int)\n",
    "            elif self.act_func =='softplus':\n",
    "                d_output *= (1 / (1 + np.exp(-activations[i+1])))\n",
    "\n",
    "            d_weights.append(np.dot(activations[i].T, d_output))\n",
    "            d_biases.append(np.sum(d_output, axis=0, keepdims=True))\n",
    "            d_output = np.dot(d_output, self.weights[i].T)\n",
    "\n",
    "        return d_weights, d_biases, loss\n",
    "\n",
    "    def train(self, inputs, labels, learning_rate, epochs):\n",
    "        start_time = time.time()\n",
    "        loss_values = []\n",
    "\n",
    "        # Initialize Adam optimization variables\n",
    "        m_weights = [np.zeros_like(w) for w in self.weights]\n",
    "        v_weights = [np.zeros_like(w) for w in self.weights]\n",
    "        m_biases = [np.zeros_like(b) for b in self.biases]\n",
    "        v_biases = [np.zeros_like(b) for b in self.biases]\n",
    "\n",
    "        beta1 = 0.9\n",
    "        beta2 = 0.999\n",
    "        epsilon = 1e-8\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            d_weights, d_biases, loss = self.back_prop(inputs, labels)\n",
    "            loss_values.append(loss)\n",
    "\n",
    "            # Update Adam optimization variables\n",
    "            for i in range(len(self.weights)):\n",
    "                m_weights[i] = beta1 * m_weights[i] + (1 - beta1) * d_weights[len(self.weights) - 1 - i]\n",
    "                v_weights[i] = beta2 * v_weights[i] + (1 - beta2) * d_weights[len(self.weights) - 1 - i]**2\n",
    "                m_biases[i] = beta1 * m_biases[i] + (1 - beta1) * d_biases[len(self.weights) - 1 - i]\n",
    "                v_biases[i] = beta2 * v_biases[i] + (1 - beta2) * d_biases[len(self.weights) - 1 - i]**2\n",
    "\n",
    "                # Update weights and biases\n",
    "                self.weights[i] -= learning_rate * m_weights[i] / (np.sqrt(v_weights[i]) + epsilon)\n",
    "                self.biases[i] -= learning_rate * (m_biases[i] / (np.sqrt(v_biases[i]) + epsilon))\n",
    "\n",
    "            print(f\"Loss at epoch {epoch}: {loss}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Training time: {end_time - start_time} seconds\")\n",
    "\n",
    "        # Plot the training loss\n",
    "        plt.plot(loss_values, label='Training Loss')\n",
    "        plt.title('Training Loss Over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def trace(self):\n",
    "        dot = Digraph(format='svg', graph_attr={'rankdir': 'LR', 'nodesep': '0.1', 'ranksep': '0.5'})  \n",
    "        nodes = []\n",
    "        edges = []\n",
    "\n",
    "        # Add input nodes\n",
    "        with dot.subgraph() as s:\n",
    "            s.attr(rank='same')\n",
    "            for i in range(self.weights[0].shape[0]):\n",
    "                node = Node(f\"Input {i}\")\n",
    "                nodes.append(node)\n",
    "                dot.node(name=str(id(node)), label=node.label, shape='circle')\n",
    "\n",
    "        # Add hidden nodes\n",
    "        hidden_nodes = []\n",
    "        for i, w in enumerate(self.weights):\n",
    "            if i < len(self.weights) - 1:\n",
    "                with dot.subgraph() as s:\n",
    "                    s.attr(rank='same')\n",
    "                    hidden_layer = []\n",
    "                    for j in range(w.shape[1]):\n",
    "                        node = Node(f\"Hidden {i} {j}\")\n",
    "                        nodes.append(node)\n",
    "                        dot.node(name=str(id(node)), label=node.label, shape='circle')\n",
    "                        hidden_layer.append(node)\n",
    "                    hidden_nodes.append(hidden_layer)\n",
    "\n",
    "        # Add output nodes\n",
    "        with dot.subgraph() as s:\n",
    "            s.attr(rank='same')\n",
    "            output_nodes = []\n",
    "            for i in range(self.weights[-1].shape[1]):\n",
    "                node = Node(f\"Output {i}\")\n",
    "                nodes.append(node)\n",
    "                dot.node(name=str(id(node)), label=node.label, shape='circle')\n",
    "                output_nodes.append(node)\n",
    "\n",
    "        # Add edges\n",
    "        for i, w in enumerate(self.weights):\n",
    "            if i == 0:  # Input to hidden\n",
    "                for j in range(w.shape[0]):\n",
    "                    for k in range(w.shape[1]):\n",
    "                        edge = Edge(nodes[j], hidden_nodes[0][k], f\"Weight {i} {j} {k}\\nValue: {w[j, k]:.2f}\")\n",
    "                        edges.append(edge)\n",
    "                        dot.edge(str(id(edge.parent)), str(id(edge.child)), label=edge.label)\n",
    "            elif i == len(self.weights) - 1:  # Hidden to output\n",
    "                for j in range(w.shape[0]):\n",
    "                    for k in range(w.shape[1]):\n",
    "                        edge = Edge(hidden_nodes[-1][j], output_nodes[k], f\"Weight {i} {j} {k}\\nValue: {w[j, k]:.2f}\")\n",
    "                        edges.append(edge)\n",
    "                        dot.edge(str(id(edge.parent)), str(id(edge.child)), label=edge.label)\n",
    "            else:  # Hidden to hidden\n",
    "                for j in range(w.shape[0]):\n",
    "                    for k in range(w.shape[1]):\n",
    "                        edge = Edge(hidden_nodes[i-1][j], hidden_nodes[i][k], f\"Weight {i} {j} {k}\\nValue: {w[j, k]:.2f}\")\n",
    "                        edges.append(edge)\n",
    "                        dot.edge(str(id(edge.parent)), str(id(edge.child)), label=edge.label)\n",
    "\n",
    "        return nodes, edges, dot\n",
    "\n",
    "    def draw_dot(self):\n",
    "        nodes, edges, dot = self.trace()\n",
    "        return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: 32.23619150296936\n",
      "Loss at epoch 1: 32.23619150296936\n",
      "Loss at epoch 2: 3.8123372410902254\n",
      "Loss at epoch 3: 2.8343732311376613\n",
      "Loss at epoch 4: 2.807616307935059\n",
      "Loss at epoch 5: 3.0353478708356127\n",
      "Loss at epoch 6: 3.290177561168316\n",
      "Loss at epoch 7: 3.4731164618997568\n",
      "Loss at epoch 8: 3.555059612626422\n",
      "Loss at epoch 9: 3.544219863650979\n",
      "Loss at epoch 10: 3.464551892050807\n",
      "Loss at epoch 11: 3.3434280008832733\n",
      "Loss at epoch 12: 3.2055420613359855\n",
      "Loss at epoch 13: 3.0704454434032225\n",
      "Loss at epoch 14: 2.952030994987528\n",
      "Loss at epoch 15: 2.8589423960242755\n",
      "Loss at epoch 16: 2.795292015533956\n",
      "Loss at epoch 17: 2.7613516155835005\n",
      "Loss at epoch 18: 2.754111757456931\n",
      "Loss at epoch 19: 2.767800874471567\n",
      "Loss at epoch 20: 2.7945839495508764\n",
      "Loss at epoch 21: 2.8256582852859538\n",
      "Loss at epoch 22: 2.852766732926045\n",
      "Loss at epoch 23: 2.8698009347702387\n",
      "Loss at epoch 24: 2.873904759605094\n",
      "Loss at epoch 25: 2.8655990675568077\n",
      "Loss at epoch 26: 2.8479312499059435\n",
      "Loss at epoch 27: 2.8251276891781867\n",
      "Loss at epoch 28: 2.801336506991728\n",
      "Loss at epoch 29: 2.779814628807835\n",
      "Loss at epoch 30: 2.7626083376225625\n",
      "Loss at epoch 31: 2.7505958906626597\n",
      "Loss at epoch 32: 2.743722959878923\n",
      "Loss at epoch 33: 2.741299724119864\n",
      "Loss at epoch 34: 2.742282243582858\n",
      "Loss at epoch 35: 2.7455028404137902\n",
      "Loss at epoch 36: 2.749839751064901\n",
      "Loss at epoch 37: 2.7543292086383375\n",
      "Loss at epoch 38: 2.7582284120514355\n",
      "Loss at epoch 39: 2.7610392522121634\n",
      "Loss at epoch 40: 2.762502359634393\n",
      "Loss at epoch 41: 2.7625700933379456\n",
      "Loss at epoch 42: 2.761365971596883\n",
      "Loss at epoch 43: 2.7591369210413452\n",
      "Loss at epoch 44: 2.756203646238187\n",
      "Loss at epoch 45: 2.752913415457781\n",
      "Loss at epoch 46: 2.749598624968043\n",
      "Loss at epoch 47: 2.7465436350347785\n",
      "Loss at epoch 48: 2.7439615397064827\n",
      "Loss at epoch 49: 2.7419817011000185\n",
      "Loss at epoch 50: 2.7406480133074287\n",
      "Loss at epoch 51: 2.7399269556938695\n",
      "Loss at epoch 52: 2.7397235955669226\n",
      "Loss at epoch 53: 2.739902910429719\n",
      "Loss at epoch 54: 2.740313267538914\n",
      "Loss at epoch 55: 2.740808770089596\n",
      "Loss at epoch 56: 2.741267542677089\n",
      "Loss at epoch 57: 2.741603861761905\n",
      "Loss at epoch 58: 2.741773192266675\n",
      "Loss at epoch 59: 2.741770428778635\n",
      "Loss at epoch 60: 2.74162269720084\n",
      "Loss at epoch 61: 2.7413787473281177\n",
      "Loss at epoch 62: 2.741097170798096\n",
      "Loss at epoch 63: 2.7408354494897536\n",
      "Loss at epoch 64: 2.7406413069850744\n",
      "Loss at epoch 65: 2.7405471689338925\n",
      "Loss at epoch 66: 2.7405678922243752\n",
      "Loss at epoch 67: 2.740701406238758\n",
      "Loss at epoch 68: 2.740931574069841\n",
      "Loss at epoch 69: 2.741232430563537\n",
      "Loss at epoch 70: 2.741572958327957\n",
      "Loss at epoch 71: 2.741921678122588\n",
      "Loss at epoch 72: 2.7422505100505052\n",
      "Loss at epoch 73: 2.742537566468977\n",
      "Loss at epoch 74: 2.7427687357353676\n",
      "Loss at epoch 75: 2.7429380869640783\n",
      "Loss at epoch 76: 2.7430472577979885\n",
      "Loss at epoch 77: 2.7431040747359168\n",
      "Loss at epoch 78: 2.7431206990475454\n",
      "Loss at epoch 79: 2.7431115948175475\n",
      "Loss at epoch 80: 2.743091585913015\n",
      "Loss at epoch 81: 2.7430742141078905\n",
      "Loss at epoch 82: 2.743070540615658\n",
      "Loss at epoch 83: 2.743088457493501\n",
      "Loss at epoch 84: 2.743132502908566\n",
      "Loss at epoch 85: 2.743204112985619\n",
      "Loss at epoch 86: 2.7433021988254174\n",
      "Loss at epoch 87: 2.743423913703141\n",
      "Loss at epoch 88: 2.7435654729725774\n",
      "Loss at epoch 89: 2.7437229055335624\n",
      "Loss at epoch 90: 2.743892646213875\n",
      "Loss at epoch 91: 2.744071916878869\n",
      "Loss at epoch 92: 2.7442588838489863\n",
      "Loss at epoch 93: 2.744452614242732\n",
      "Loss at epoch 94: 2.744652879674328\n",
      "Loss at epoch 95: 2.7448598699088764\n",
      "Loss at epoch 96: 2.7450738813933837\n",
      "Loss at epoch 97: 2.7452950377120757\n",
      "Loss at epoch 98: 2.7455230839351623\n",
      "Loss at epoch 99: 2.7457572781055806\n",
      "Loss at epoch 100: 2.7459963842069834\n",
      "Loss at epoch 101: 2.746238754720962\n",
      "Loss at epoch 102: 2.746482479212936\n",
      "Loss at epoch 103: 2.7467255691459393\n",
      "Loss at epoch 104: 2.7469661482189567\n",
      "Loss at epoch 105: 2.7472026211283334\n",
      "Loss at epoch 106: 2.7474338004523773\n",
      "Loss at epoch 107: 2.747658979860426\n",
      "Loss at epoch 108: 2.747877950595161\n",
      "Loss at epoch 109: 2.7480909659483306\n",
      "Loss at epoch 110: 2.7482986643699285\n",
      "Loss at epoch 111: 2.748501965440898\n",
      "Loss at epoch 112: 2.748701954108908\n",
      "Loss at epoch 113: 2.7488997675786644\n",
      "Loss at epoch 114: 2.7490964965524003\n",
      "Loss at epoch 115: 2.7492931087665773\n",
      "Loss at epoch 116: 2.7494903986404604\n",
      "Loss at epoch 117: 2.7496889629580687\n",
      "Loss at epoch 118: 2.7498891993337637\n",
      "Loss at epoch 119: 2.7500913220727305\n",
      "Loss at epoch 120: 2.7502953890462973\n",
      "Loss at epoch 121: 2.750501333292502\n",
      "Loss at epoch 122: 2.750708994013834\n",
      "Loss at epoch 123: 2.7509181431741636\n",
      "Loss at epoch 124: 2.7511285056599215\n",
      "Loss at epoch 125: 2.7513397726536337\n",
      "Loss at epoch 126: 2.7515516092246184\n",
      "Loss at epoch 127: 2.751763658019178\n",
      "Loss at epoch 128: 2.7519755412801086\n",
      "Loss at epoch 129: 2.7521868632846975\n",
      "Loss at epoch 130: 2.7523972147742146\n",
      "Loss at epoch 131: 2.7526061802096393\n",
      "Loss at epoch 132: 2.752813347891362\n",
      "Loss at epoch 133: 2.7530183222703286\n",
      "Loss at epoch 134: 2.753220737262536\n",
      "Loss at epoch 135: 2.7534202691175027\n",
      "Loss at epoch 136: 2.7536166473943275\n",
      "Loss at epoch 137: 2.7538096628330595\n",
      "Loss at epoch 138: 2.753999171310296\n",
      "Loss at epoch 139: 2.7541850935557566\n",
      "Loss at epoch 140: 2.754367410799248\n",
      "Loss at epoch 141: 2.754546156943957\n",
      "Loss at epoch 142: 2.754721408171424\n",
      "Loss at epoch 143: 2.7548932710491076\n",
      "Loss at epoch 144: 2.7550618702307395\n",
      "Loss at epoch 145: 2.755227336731527\n",
      "Loss at epoch 146: 2.7553897975579846\n",
      "Loss at epoch 147: 2.7555493672172573\n",
      "Loss at epoch 148: 2.7557061413646657\n",
      "Loss at epoch 149: 2.7558601926069315\n",
      "Loss at epoch 150: 2.756011568288042\n",
      "Loss at epoch 151: 2.756160289958796\n",
      "Loss at epoch 152: 2.756306354171702\n",
      "Loss at epoch 153: 2.7564497342418424\n",
      "Loss at epoch 154: 2.756590382656377\n",
      "Loss at epoch 155: 2.7567282338823036\n",
      "Loss at epoch 156: 2.756863207395603\n",
      "Loss at epoch 157: 2.7569952108203557\n",
      "Loss at epoch 158: 2.757124143113548\n",
      "Loss at epoch 159: 2.7572498977563518\n",
      "Loss at epoch 160: 2.757372365916374\n",
      "Loss at epoch 161: 2.757491439533215\n",
      "Loss at epoch 162: 2.7576070142592988\n",
      "Loss at epoch 163: 2.7577189921673035\n",
      "Loss at epoch 164: 2.757827284122075\n",
      "Loss at epoch 165: 2.7579318117132616\n",
      "Loss at epoch 166: 2.7580325086574033\n",
      "Loss at epoch 167: 2.7581293216037968\n",
      "Loss at epoch 168: 2.758222210314182\n",
      "Loss at epoch 169: 2.758311147227319\n",
      "Loss at epoch 170: 2.7583961164604247\n",
      "Loss at epoch 171: 2.7584771123353704\n",
      "Loss at epoch 172: 2.7585541375443423\n",
      "Loss at epoch 173: 2.758627201085099\n",
      "Loss at epoch 174: 2.7586963160992273\n",
      "Loss at epoch 175: 2.75876149773891\n",
      "Loss at epoch 176: 2.758822761170811\n",
      "Loss at epoch 177: 2.7588801198026993\n",
      "Loss at epoch 178: 2.758933583792579\n",
      "Loss at epoch 179: 2.7589831588743525\n",
      "Loss at epoch 180: 2.7590288455106733\n",
      "Loss at epoch 181: 2.7590706383643773\n",
      "Loss at epoch 182: 2.759108526065311\n",
      "Loss at epoch 183: 2.7591424912394955\n",
      "Loss at epoch 184: 2.7591725107618674\n",
      "Loss at epoch 185: 2.7591985561912757\n",
      "Loss at epoch 186: 2.759220594346118\n",
      "Loss at epoch 187: 2.7592385879799517\n",
      "Loss at epoch 188: 2.7592524965180822\n",
      "Loss at epoch 189: 2.75926227681805\n",
      "Loss at epoch 190: 2.759267883919115\n",
      "Loss at epoch 191: 2.75926927174835\n",
      "Loss at epoch 192: 2.759266393754066\n",
      "Loss at epoch 193: 2.759259203441192\n",
      "Loss at epoch 194: 2.7592476547881244\n",
      "Loss at epoch 195: 2.7592317025303394\n",
      "Loss at epoch 196: 2.7592113023026434\n",
      "Loss at epoch 197: 2.7591864106388626\n",
      "Loss at epoch 198: 2.759156984834712\n",
      "Loss at epoch 199: 2.7591229826859967\n",
      "Loss at epoch 200: 2.759084362119678\n",
      "Loss at epoch 201: 2.759041080739502\n",
      "Loss at epoch 202: 2.758993095310363\n",
      "Loss at epoch 203: 2.758940361206501\n",
      "Loss at epoch 204: 2.7588828318480054\n",
      "Loss at epoch 205: 2.758820458148069\n",
      "Loss at epoch 206: 2.7587531879903873\n",
      "Loss at epoch 207: 2.7586809657523528\n",
      "Loss at epoch 208: 2.7586037318855037\n",
      "Loss at epoch 209: 2.758521422560475\n",
      "Loss at epoch 210: 2.7584339693796736\n",
      "Loss at epoch 211: 2.758341299157182\n",
      "Loss at epoch 212: 2.758243333762253\n",
      "Loss at epoch 213: 2.758139990020086\n",
      "Loss at epoch 214: 2.758031179661499\n",
      "Loss at epoch 215: 2.757916809311625\n",
      "Loss at epoch 216: 2.757796780506724\n",
      "Loss at epoch 217: 2.75767098972774\n",
      "Loss at epoch 218: 2.757539328439177\n",
      "Loss at epoch 219: 2.7574016831222816\n",
      "Loss at epoch 220: 2.7572579352922832\n",
      "Loss at epoch 221: 2.7571079614906067\n",
      "Loss at epoch 222: 2.7569516332443955\n",
      "Loss at epoch 223: 2.756788816987358\n",
      "Loss at epoch 224: 2.7566193739377716\n",
      "Loss at epoch 225: 2.7564431599313846\n",
      "Loss at epoch 226: 2.75626002520877\n",
      "Loss at epoch 227: 2.756069814158485\n",
      "Loss at epoch 228: 2.7558723650188472\n",
      "Loss at epoch 229: 2.7556675095424383\n",
      "Loss at epoch 230: 2.755455072628354\n",
      "Loss at epoch 231: 2.755234871927768\n",
      "Loss at epoch 232: 2.7550067174286355\n",
      "Loss at epoch 233: 2.7547704110251967\n",
      "Loss at epoch 234: 2.75452574607755\n",
      "Loss at epoch 235: 2.754272506965868\n",
      "Loss at epoch 236: 2.7540104686429725\n",
      "Loss at epoch 237: 2.753739396187974\n",
      "Loss at epoch 238: 2.75345904436261\n",
      "Loss at epoch 239: 2.753169157170822\n",
      "Loss at epoch 240: 2.752869467421036\n",
      "Loss at epoch 241: 2.752559696289657\n",
      "Loss at epoch 242: 2.7522395528833568\n",
      "Loss at epoch 243: 2.751908733797068\n",
      "Loss at epoch 244: 2.7515669226639528\n",
      "Loss at epoch 245: 2.751213789693228\n",
      "Loss at epoch 246: 2.7508489911915133\n",
      "Loss at epoch 247: 2.750472169063255\n",
      "Loss at epoch 248: 2.7500829502859316\n",
      "Loss at epoch 249: 2.7496809463559573\n",
      "Loss at epoch 250: 2.7492657527015916\n",
      "Loss at epoch 251: 2.748836948059653\n",
      "Loss at epoch 252: 2.7483940938133595\n",
      "Loss at epoch 253: 2.7479367332892393\n",
      "Loss at epoch 254: 2.7474643910116523\n",
      "Loss at epoch 255: 2.746976571914012\n",
      "Loss at epoch 256: 2.7464727605063852\n",
      "Loss at epoch 257: 2.7459524199995515\n",
      "Loss at epoch 258: 2.7454149913859904\n",
      "Loss at epoch 259: 2.744859892478526\n",
      "Loss at epoch 260: 2.7442865169074953\n",
      "Loss at epoch 261: 2.743694233077349\n",
      "Loss at epoch 262: 2.743082383083524\n",
      "Loss at epoch 263: 2.742450281590257\n",
      "Loss at epoch 264: 2.741797214669753\n",
      "Loss at epoch 265: 2.741122438602841\n",
      "Loss at epoch 266: 2.7404251786408436\n",
      "Loss at epoch 267: 2.7397046277280714\n",
      "Loss at epoch 268: 2.7389599451839017\n",
      "Loss at epoch 269: 2.7381902553430875\n",
      "Loss at epoch 270: 2.737394646152588\n",
      "Loss at epoch 271: 2.736572167722914\n",
      "Loss at epoch 272: 2.7357218308317828\n",
      "Loss at epoch 273: 2.7348426053777173\n",
      "Loss at epoch 274: 2.7339334187811097\n",
      "Loss at epoch 275: 2.732993154330331\n",
      "Loss at epoch 276: 2.73202064947049\n",
      "Loss at epoch 277: 2.731014694032559\n",
      "Loss at epoch 278: 2.729974028400871\n",
      "Loss at epoch 279: 2.728897341617075\n",
      "Loss at epoch 280: 2.727783269419047\n",
      "Loss at epoch 281: 2.726630392213384\n",
      "Loss at epoch 282: 2.725437232980441\n",
      "Loss at epoch 283: 2.7242022551110487\n",
      "Loss at epoch 284: 2.7229238601742125\n",
      "Loss at epoch 285: 2.7216003856152016\n",
      "Loss at epoch 286: 2.720230102383405\n",
      "Loss at epoch 287: 2.7188112124892667\n",
      "Loss at epoch 288: 2.717341846489332\n",
      "Loss at epoch 289: 2.7158200608981375\n",
      "Loss at epoch 290: 2.714243835525121\n",
      "Loss at epoch 291: 2.7126110707341096\n",
      "Loss at epoch 292: 2.710919584622112\n",
      "Loss at epoch 293: 2.7091671101131825\n",
      "Loss at epoch 294: 2.7073512919619556\n",
      "Loss at epoch 295: 2.7054696836601653\n",
      "Loss at epoch 296: 2.703519744237955\n",
      "Loss at epoch 297: 2.701498834950118\n",
      "Loss at epoch 298: 2.6994042158355684\n",
      "Loss at epoch 299: 2.6972330421363195\n",
      "Loss at epoch 300: 2.694982360560016\n",
      "Loss at epoch 301: 2.6926491053676864\n",
      "Loss at epoch 302: 2.690230094265788\n",
      "Loss at epoch 303: 2.687722024078841\n",
      "Loss at epoch 304: 2.6851214661760197\n",
      "Loss at epoch 305: 2.6824248616219206\n",
      "Loss at epoch 306: 2.6796285160184783\n",
      "Loss at epoch 307: 2.6767285940015797\n",
      "Loss at epoch 308: 2.6737211133524155\n",
      "Loss at epoch 309: 2.6706019386800435\n",
      "Loss at epoch 310: 2.667366774628095\n",
      "Loss at epoch 311: 2.6640111585550086\n",
      "Loss at epoch 312: 2.6605304526338887\n",
      "Loss at epoch 313: 2.65691983531497\n",
      "Loss at epoch 314: 2.6531742920909855\n",
      "Loss at epoch 315: 2.649288605503579\n",
      "Loss at epoch 316: 2.6452573443273835\n",
      "Loss at epoch 317: 2.641074851867817\n",
      "Loss at epoch 318: 2.6367352333090013\n",
      "Loss at epoch 319: 2.6322323420499667\n",
      "Loss at epoch 320: 2.6275597649704157\n",
      "Loss at epoch 321: 2.6227108065721385\n",
      "Loss at epoch 322: 2.617678471948939\n",
      "Loss at epoch 323: 2.6124554485467444\n",
      "Loss at epoch 324: 2.6070340866866797\n",
      "Loss at epoch 325: 2.6014063788375386\n",
      "Loss at epoch 326: 2.5955639376402146\n",
      "Loss at epoch 327: 2.5894979727056535\n",
      "Loss at epoch 328: 2.5831992662295242\n",
      "Loss at epoch 329: 2.5766581474913584\n",
      "Loss at epoch 330: 2.56986446633311\n",
      "Loss at epoch 331: 2.562807565742022\n",
      "Loss at epoch 332: 2.5554762536950286\n",
      "Loss at epoch 333: 2.5478587744565666\n",
      "Loss at epoch 334: 2.5399427795581957\n",
      "Loss at epoch 335: 2.5317152987265077\n",
      "Loss at epoch 336: 2.523162711065004\n",
      "Loss at epoch 337: 2.5142707168352647\n",
      "Loss at epoch 338: 2.505024310222442\n",
      "Loss at epoch 339: 2.49540775350892\n",
      "Loss at epoch 340: 2.485404553117385\n",
      "Loss at epoch 341: 2.4749974380195425\n",
      "Loss at epoch 342: 2.4641683410384934\n",
      "Loss at epoch 343: 2.452898383600461\n",
      "Loss at epoch 344: 2.44116786451402\n",
      "Loss at epoch 345: 2.428956253371459\n",
      "Loss at epoch 346: 2.416242189176342\n",
      "Loss at epoch 347: 2.4030034848029027\n",
      "Loss at epoch 348: 2.3892171378859306\n",
      "Loss at epoch 349: 2.374859348723773\n",
      "Loss at epoch 350: 2.3599055457517957\n",
      "Loss at epoch 351: 2.344330419109494\n",
      "Loss at epoch 352: 2.3281079627821573\n",
      "Loss at epoch 353: 2.3112115257493455\n",
      "Loss at epoch 354: 2.293613872519929\n",
      "Loss at epoch 355: 2.2752872533808293\n",
      "Loss at epoch 356: 2.2562034846389665\n",
      "Loss at epoch 357: 2.236334039099846\n",
      "Loss at epoch 358: 2.2156501470099466\n",
      "Loss at epoch 359: 2.194122907703637\n",
      "Loss at epoch 360: 2.171723412250328\n",
      "Loss at epoch 361: 2.14842287750726\n",
      "Loss at epoch 362: 2.124192792161841\n",
      "Loss at epoch 363: 2.099005075609673\n",
      "Loss at epoch 364: 2.0728322508743773\n",
      "Loss at epoch 365: 2.0456476332454656\n",
      "Loss at epoch 366: 2.0174255368994847\n",
      "Loss at epoch 367: 1.9881415024802611\n",
      "Loss at epoch 368: 1.95777254944048\n",
      "Loss at epoch 369: 1.926297457871283\n",
      "Loss at epoch 370: 1.8936970855353383\n",
      "Loss at epoch 371: 1.8599547268181649\n",
      "Loss at epoch 372: 1.8250565212431904\n",
      "Loss at epoch 373: 1.7889919199489752\n",
      "Loss at epoch 374: 1.751754218957864\n",
      "Loss at epoch 375: 1.7133411679911839\n",
      "Loss at epoch 376: 1.6737556627842527\n",
      "Loss at epoch 377: 1.6330065270665193\n",
      "Loss at epoch 378: 1.591109387314917\n",
      "Loss at epoch 379: 1.548087638776912\n",
      "Loss at epoch 380: 1.5039734948429486\n",
      "Loss at epoch 381: 1.4588091034623176\n",
      "Loss at epoch 382: 1.4126477039332281\n",
      "Loss at epoch 383: 1.365554785281273\n",
      "Loss at epoch 384: 1.3176091941042778\n",
      "Loss at epoch 385: 1.2689041261061043\n",
      "Loss at epoch 386: 1.2195479228487147\n",
      "Loss at epoch 387: 1.169664585130509\n",
      "Loss at epoch 388: 1.1193939086512361\n",
      "Loss at epoch 389: 1.0688911480232783\n",
      "Loss at epoch 390: 1.0183261232117877\n",
      "Loss at epoch 391: 0.9678816990569867\n",
      "Loss at epoch 392: 0.9177515938798133\n",
      "Loss at epoch 393: 0.8681375068661087\n",
      "Loss at epoch 394: 0.8192455950805129\n",
      "Loss at epoch 395: 0.77128237846058\n",
      "Loss at epoch 396: 0.7244502035537909\n",
      "Loss at epoch 397: 0.6789424516493892\n",
      "Loss at epoch 398: 0.6349387295399387\n",
      "Loss at epoch 399: 0.5926003228873401\n",
      "Loss at epoch 400: 0.5520662106218931\n",
      "Loss at epoch 401: 0.5134499202694447\n",
      "Loss at epoch 402: 0.47683743967554326\n",
      "Loss at epoch 403: 0.44228629390315866\n",
      "Loss at epoch 404: 0.4098257681880205\n",
      "Loss at epoch 405: 0.37945814380332094\n",
      "Loss at epoch 406: 0.3511607482946019\n",
      "Loss at epoch 407: 0.3248886190705894\n",
      "Loss at epoch 408: 0.30057762001762267\n",
      "Loss at epoch 409: 0.27814788782316946\n",
      "Loss at epoch 410: 0.2575074745876669\n",
      "Loss at epoch 411: 0.2385559932280116\n",
      "Loss at epoch 412: 0.2211880134175449\n",
      "Loss at epoch 413: 0.20529597192741825\n",
      "Loss at epoch 414: 0.1907724840743824\n",
      "Loss at epoch 415: 0.1775121172916416\n",
      "Loss at epoch 416: 0.1654127967141333\n",
      "Loss at epoch 417: 0.15437697262476807\n",
      "Loss at epoch 418: 0.14431253021302415\n",
      "Loss at epoch 419: 0.13513331419275687\n",
      "Loss at epoch 420: 0.1267592052963946\n",
      "Loss at epoch 421: 0.1191158908184306\n",
      "Loss at epoch 422: 0.11213462284567767\n",
      "Loss at epoch 423: 0.10575217792605801\n",
      "Loss at epoch 424: 0.09991095986322396\n",
      "Loss at epoch 425: 0.09455897597627895\n",
      "Loss at epoch 426: 0.08964948673574737\n",
      "Loss at epoch 427: 0.08514041582392909\n",
      "Loss at epoch 428: 0.08099380456596561\n",
      "Loss at epoch 429: 0.07717547967296516\n",
      "Loss at epoch 430: 0.07365480874765439\n",
      "Loss at epoch 431: 0.07040429981590293\n",
      "Loss at epoch 432: 0.06739901875096092\n",
      "Loss at epoch 433: 0.06461609737972698\n",
      "Loss at epoch 434: 0.0620346018111376\n",
      "Loss at epoch 435: 0.05963569126257553\n",
      "Loss at epoch 436: 0.05740271189850345\n",
      "Loss at epoch 437: 0.05532098396673775\n",
      "Loss at epoch 438: 0.05337741265784728\n",
      "Loss at epoch 439: 0.05156022040001163\n",
      "Loss at epoch 440: 0.049858869721302\n",
      "Loss at epoch 441: 0.048263954691908376\n",
      "Loss at epoch 442: 0.04676689627677234\n",
      "Loss at epoch 443: 0.04535960699897048\n",
      "Loss at epoch 444: 0.04403442472008584\n",
      "Loss at epoch 445: 0.04278434042571111\n",
      "Loss at epoch 446: 0.04160321305055949\n",
      "Loss at epoch 447: 0.04048571639489003\n",
      "Loss at epoch 448: 0.03942711544896566\n",
      "Loss at epoch 449: 0.03842313506641819\n",
      "Loss at epoch 450: 0.03746996442195314\n",
      "Loss at epoch 451: 0.03656419620962014\n",
      "Loss at epoch 452: 0.03570260589787773\n",
      "Loss at epoch 453: 0.03488196725115188\n",
      "Loss at epoch 454: 0.03409912157614457\n",
      "Loss at epoch 455: 0.03335121479745911\n",
      "Loss at epoch 456: 0.03263582014607924\n",
      "Loss at epoch 457: 0.03195084778817078\n",
      "Loss at epoch 458: 0.03129441939163806\n",
      "Loss at epoch 459: 0.030664856769226013\n",
      "Loss at epoch 460: 0.03006068942674335\n",
      "Loss at epoch 461: 0.029480537181948346\n",
      "Loss at epoch 462: 0.028922946875901072\n",
      "Loss at epoch 463: 0.028386387440871103\n",
      "Loss at epoch 464: 0.027869418426973745\n",
      "Loss at epoch 465: 0.027370825476162916\n",
      "Loss at epoch 466: 0.026889592402265787\n",
      "Loss at epoch 467: 0.026424815413855243\n",
      "Loss at epoch 468: 0.02597569350199656\n",
      "Loss at epoch 469: 0.025541542931837316\n",
      "Loss at epoch 470: 0.025121719093962276\n",
      "Loss at epoch 471: 0.02471549538806328\n",
      "Loss at epoch 472: 0.024322057234334202\n",
      "Loss at epoch 473: 0.02394062566180079\n",
      "Loss at epoch 474: 0.023570553801186275\n",
      "Loss at epoch 475: 0.023211306063392834\n",
      "Loss at epoch 476: 0.022862407010101865\n",
      "Loss at epoch 477: 0.022523447044141498\n",
      "Loss at epoch 478: 0.02219408764658692\n",
      "Loss at epoch 479: 0.021873991062180197\n",
      "Loss at epoch 480: 0.02156273961394713\n",
      "Loss at epoch 481: 0.021259855876289833\n",
      "Loss at epoch 482: 0.020964897410188896\n",
      "Loss at epoch 483: 0.020677504432219558\n",
      "Loss at epoch 484: 0.02039737273593243\n",
      "Loss at epoch 485: 0.020124233552424868\n",
      "Loss at epoch 486: 0.019857869264360617\n",
      "Loss at epoch 487: 0.01959809872610352\n",
      "Loss at epoch 488: 0.019344711298478746\n",
      "Loss at epoch 489: 0.019097430958421972\n",
      "Loss at epoch 490: 0.01885596114268915\n",
      "Loss at epoch 491: 0.018620045348874792\n",
      "Loss at epoch 492: 0.018389472758900682\n",
      "Loss at epoch 493: 0.018164057529030088\n",
      "Loss at epoch 494: 0.017943644352729\n",
      "Loss at epoch 495: 0.017728115478218776\n",
      "Loss at epoch 496: 0.01751735481305371\n",
      "Loss at epoch 497: 0.017311203091411778\n",
      "Loss at epoch 498: 0.017109466226559157\n",
      "Loss at epoch 499: 0.016911960941316865\n",
      "Loss at epoch 500: 0.01671853437909742\n",
      "Loss at epoch 501: 0.016529052403580942\n",
      "Loss at epoch 502: 0.01634339938075293\n",
      "Loss at epoch 503: 0.016161489030598213\n",
      "Loss at epoch 504: 0.015983247798841388\n",
      "Loss at epoch 505: 0.015808578262178605\n",
      "Loss at epoch 506: 0.015637352258553512\n",
      "Loss at epoch 507: 0.015469439672726779\n",
      "Loss at epoch 508: 0.015304728131451967\n",
      "Loss at epoch 509: 0.015143117934754716\n",
      "Loss at epoch 510: 0.01498452117968784\n",
      "Loss at epoch 511: 0.0148288716669247\n",
      "Loss at epoch 512: 0.014676117073975332\n",
      "Loss at epoch 513: 0.014526192111401229\n",
      "Loss at epoch 514: 0.01437900881813275\n",
      "Loss at epoch 515: 0.014234474361697867\n",
      "Loss at epoch 516: 0.014092505760019582\n",
      "Loss at epoch 517: 0.013953027514707554\n",
      "Loss at epoch 518: 0.01381597202674674\n",
      "Loss at epoch 519: 0.013681287994919435\n",
      "Loss at epoch 520: 0.013548935545204548\n",
      "Loss at epoch 521: 0.013418866743781191\n",
      "Loss at epoch 522: 0.0132910181070904\n",
      "Loss at epoch 523: 0.01316532240634499\n",
      "Loss at epoch 524: 0.013041717849825383\n",
      "Loss at epoch 525: 0.012920146387014348\n",
      "Loss at epoch 526: 0.01280055578122681\n",
      "Loss at epoch 527: 0.012682906413878089\n",
      "Loss at epoch 528: 0.012567166634984833\n",
      "Loss at epoch 529: 0.012453298617567714\n",
      "Loss at epoch 530: 0.012341254494380852\n",
      "Loss at epoch 531: 0.012230984680125742\n",
      "Loss at epoch 532: 0.012122442377887104\n",
      "Loss at epoch 533: 0.012015582290909647\n",
      "Loss at epoch 534: 0.011910364150876044\n",
      "Loss at epoch 535: 0.011806757499191911\n",
      "Loss at epoch 536: 0.011704736313089105\n",
      "Loss at epoch 537: 0.01160426929718731\n",
      "Loss at epoch 538: 0.01150531938402833\n",
      "Loss at epoch 539: 0.011407849278823518\n",
      "Loss at epoch 540: 0.011311822616595553\n",
      "Loss at epoch 541: 0.011217203695419457\n",
      "Loss at epoch 542: 0.011123961780260316\n",
      "Loss at epoch 543: 0.01103207328348487\n",
      "Loss at epoch 544: 0.010941515978952782\n",
      "Loss at epoch 545: 0.010852263453694201\n",
      "Loss at epoch 546: 0.0107642867161035\n",
      "Loss at epoch 547: 0.010677556977340456\n",
      "Loss at epoch 548: 0.010592045162171073\n",
      "Loss at epoch 549: 0.010507723206938198\n",
      "Loss at epoch 550: 0.010424567911669281\n",
      "Loss at epoch 551: 0.010342560399452617\n",
      "Loss at epoch 552: 0.010261681114382613\n",
      "Loss at epoch 553: 0.010181907910427536\n",
      "Loss at epoch 554: 0.010103217971552201\n",
      "Loss at epoch 555: 0.01002558823742905\n",
      "Loss at epoch 556: 0.009948995086253114\n",
      "Loss at epoch 557: 0.009873416854425917\n",
      "Loss at epoch 558: 0.009798835898527682\n",
      "Loss at epoch 559: 0.009725236256956968\n",
      "Loss at epoch 560: 0.009652600697706609\n",
      "Loss at epoch 561: 0.009580911029741795\n",
      "Loss at epoch 562: 0.009510148886548055\n",
      "Loss at epoch 563: 0.009440295129207348\n",
      "Loss at epoch 564: 0.009371330784335247\n",
      "Loss at epoch 565: 0.00930323941528401\n",
      "Loss at epoch 566: 0.009236006950643853\n",
      "Loss at epoch 567: 0.00916961933935905\n",
      "Loss at epoch 568: 0.0091040618341204\n",
      "Loss at epoch 569: 0.009039319570203031\n",
      "Loss at epoch 570: 0.008975377138847829\n",
      "Loss at epoch 571: 0.008912218578030137\n",
      "Loss at epoch 572: 0.008849829111560785\n",
      "Loss at epoch 573: 0.008788196017642361\n",
      "Loss at epoch 574: 0.00872730730159638\n",
      "Loss at epoch 575: 0.008667150701059534\n",
      "Loss at epoch 576: 0.00860771394035155\n",
      "Loss at epoch 577: 0.008548984475712949\n",
      "Loss at epoch 578: 0.008490949090059308\n",
      "Loss at epoch 579: 0.008433594909947374\n",
      "Loss at epoch 580: 0.008376910509884528\n",
      "Loss at epoch 581: 0.008320885375417291\n",
      "Loss at epoch 582: 0.008265509052653025\n",
      "Loss at epoch 583: 0.008210771196695561\n",
      "Loss at epoch 584: 0.00815666141099697\n",
      "Loss at epoch 585: 0.008103168741364412\n",
      "Loss at epoch 586: 0.008050282172275585\n",
      "Loss at epoch 587: 0.00799799159638431\n",
      "Loss at epoch 588: 0.0079462877182533\n",
      "Loss at epoch 589: 0.007895161465571439\n",
      "Loss at epoch 590: 0.007844603970072408\n",
      "Loss at epoch 591: 0.007794606454434723\n",
      "Loss at epoch 592: 0.007745159748972731\n",
      "Loss at epoch 593: 0.007696254485047526\n",
      "Loss at epoch 594: 0.007647881831179221\n",
      "Loss at epoch 595: 0.007600033576037325\n",
      "Loss at epoch 596: 0.007552701768897525\n",
      "Loss at epoch 597: 0.007505878713234545\n",
      "Loss at epoch 598: 0.007459556881488219\n",
      "Loss at epoch 599: 0.007413728495427225\n",
      "Loss at epoch 600: 0.0073683855727360555\n",
      "Loss at epoch 601: 0.007323520447989155\n",
      "Loss at epoch 602: 0.007279125889736681\n",
      "Loss at epoch 603: 0.007235194900506585\n",
      "Loss at epoch 604: 0.007191720748977949\n",
      "Loss at epoch 605: 0.0071486969013646266\n",
      "Loss at epoch 606: 0.007106116673557208\n",
      "Loss at epoch 607: 0.0070639732245309575\n",
      "Loss at epoch 608: 0.007022259911465774\n",
      "Loss at epoch 609: 0.006980970378196895\n",
      "Loss at epoch 610: 0.006940098456768277\n",
      "Loss at epoch 611: 0.006899638233889852\n",
      "Loss at epoch 612: 0.006859583988426836\n",
      "Loss at epoch 613: 0.006819929912681733\n",
      "Loss at epoch 614: 0.006780670101904976\n",
      "Loss at epoch 615: 0.006741798787892855\n",
      "Loss at epoch 616: 0.006703310383141317\n",
      "Loss at epoch 617: 0.0066651994475020754\n",
      "Loss at epoch 618: 0.006627460772572363\n",
      "Loss at epoch 619: 0.006590089315967446\n",
      "Loss at epoch 620: 0.0065530799880239386\n",
      "Loss at epoch 621: 0.006516427657196063\n",
      "Loss at epoch 622: 0.006480127293510348\n",
      "Loss at epoch 623: 0.006444173976063368\n",
      "Loss at epoch 624: 0.006408562904135893\n",
      "Loss at epoch 625: 0.006373289480350668\n",
      "Loss at epoch 626: 0.006338349237584543\n",
      "Loss at epoch 627: 0.0063037376877162375\n",
      "Loss at epoch 628: 0.006269450344265303\n",
      "Loss at epoch 629: 0.0062354827969096265\n",
      "Loss at epoch 630: 0.006201830699819441\n",
      "Loss at epoch 631: 0.006168489813523786\n",
      "Loss at epoch 632: 0.006135456069776422\n",
      "Loss at epoch 633: 0.006102725494064232\n",
      "Loss at epoch 634: 0.0060702941124258164\n",
      "Loss at epoch 635: 0.0060381579811824\n",
      "Loss at epoch 636: 0.006006313209911204\n",
      "Loss at epoch 637: 0.005974755950096909\n",
      "Loss at epoch 638: 0.0059434824535868\n",
      "Loss at epoch 639: 0.005912489108117402\n",
      "Loss at epoch 640: 0.0058817723655623655\n",
      "Loss at epoch 641: 0.005851328698096275\n",
      "Loss at epoch 642: 0.005821154620604741\n",
      "Loss at epoch 643: 0.005791246681358382\n",
      "Loss at epoch 644: 0.005761601464978449\n",
      "Loss at epoch 645: 0.005732215650845052\n",
      "Loss at epoch 646: 0.00570308601829873\n",
      "Loss at epoch 647: 0.005674209393031132\n",
      "Loss at epoch 648: 0.005645582636942464\n",
      "Loss at epoch 649: 0.00561720265278724\n",
      "Loss at epoch 650: 0.005589066363638642\n",
      "Loss at epoch 651: 0.005561170733855257\n",
      "Loss at epoch 652: 0.005533512811467779\n",
      "Loss at epoch 653: 0.0055060897131271125\n",
      "Loss at epoch 654: 0.005478898596405118\n",
      "Loss at epoch 655: 0.005451936662706185\n",
      "Loss at epoch 656: 0.00542520114379065\n",
      "Loss at epoch 657: 0.005398689288990241\n",
      "Loss at epoch 658: 0.005372398395341133\n",
      "Loss at epoch 659: 0.005346325826079006\n",
      "Loss at epoch 660: 0.005320468992323385\n",
      "Loss at epoch 661: 0.0052948253476832905\n",
      "Loss at epoch 662: 0.005269392386517306\n",
      "Loss at epoch 663: 0.005244167623337948\n",
      "Loss at epoch 664: 0.005219148595900109\n",
      "Loss at epoch 665: 0.005194332889818564\n",
      "Loss at epoch 666: 0.005169718138303567\n",
      "Loss at epoch 667: 0.005145302014080368\n",
      "Loss at epoch 668: 0.005121082232553099\n",
      "Loss at epoch 669: 0.005097056539673348\n",
      "Loss at epoch 670: 0.005073222698474687\n",
      "Loss at epoch 671: 0.005049578502053153\n",
      "Loss at epoch 672: 0.00502612178363207\n",
      "Loss at epoch 673: 0.005002850411688372\n",
      "Loss at epoch 674: 0.004979762292963361\n",
      "Loss at epoch 675: 0.004956855370679987\n",
      "Loss at epoch 676: 0.00493412760941219\n",
      "Loss at epoch 677: 0.0049115769944603595\n",
      "Loss at epoch 678: 0.004889201541967223\n",
      "Loss at epoch 679: 0.0048669992983902\n",
      "Loss at epoch 680: 0.004844968341639165\n",
      "Loss at epoch 681: 0.004823106785363151\n",
      "Loss at epoch 682: 0.0048014127699219505\n",
      "Loss at epoch 683: 0.0047798844544980675\n",
      "Loss at epoch 684: 0.0047585200223789915\n",
      "Loss at epoch 685: 0.004737317682503084\n",
      "Loss at epoch 686: 0.004716275668980058\n",
      "Loss at epoch 687: 0.004695392246821977\n",
      "Loss at epoch 688: 0.004674665709650292\n",
      "Loss at epoch 689: 0.004654094371301819\n",
      "Loss at epoch 690: 0.004633676566200022\n",
      "Loss at epoch 691: 0.004613410650966909\n",
      "Loss at epoch 692: 0.004593295002975814\n",
      "Loss at epoch 693: 0.0045733280245143625\n",
      "Loss at epoch 694: 0.00455350814495888\n",
      "Loss at epoch 695: 0.004533833815066988\n",
      "Loss at epoch 696: 0.004514303504774139\n",
      "Loss at epoch 697: 0.004494915704083181\n",
      "Loss at epoch 698: 0.004475668921047562\n",
      "Loss at epoch 699: 0.004456561683660091\n",
      "Loss at epoch 700: 0.004437592543625682\n",
      "Loss at epoch 701: 0.0044187600736259\n",
      "Loss at epoch 702: 0.0044000628648578535\n",
      "Loss at epoch 703: 0.00438149952721871\n",
      "Loss at epoch 704: 0.004363068687186013\n",
      "Loss at epoch 705: 0.004344768987823301\n",
      "Loss at epoch 706: 0.004326599092166918\n",
      "Loss at epoch 707: 0.004308557682690033\n",
      "Loss at epoch 708: 0.004290643459367773\n",
      "Loss at epoch 709: 0.004272855139827812\n",
      "Loss at epoch 710: 0.004255191457440742\n",
      "Loss at epoch 711: 0.004237651160103087\n",
      "Loss at epoch 712: 0.004220233012569151\n",
      "Loss at epoch 713: 0.004202935796959275\n",
      "Loss at epoch 714: 0.004185758311472004\n",
      "Loss at epoch 715: 0.004168699370782594\n",
      "Loss at epoch 716: 0.004151757804649323\n",
      "Loss at epoch 717: 0.004134932456127165\n",
      "Loss at epoch 718: 0.004118222182874311\n",
      "Loss at epoch 719: 0.0041016258577856205\n",
      "Loss at epoch 720: 0.004085142368287118\n",
      "Loss at epoch 721: 0.0040687706169312676\n",
      "Loss at epoch 722: 0.004052509520498366\n",
      "Loss at epoch 723: 0.0040363580083028604\n",
      "Loss at epoch 724: 0.004020315022677945\n",
      "Loss at epoch 725: 0.004004379519388245\n",
      "Loss at epoch 726: 0.003988550467202649\n",
      "Loss at epoch 727: 0.003972826848552293\n",
      "Loss at epoch 728: 0.003957207659135671\n",
      "Loss at epoch 729: 0.003941691906485309\n",
      "Loss at epoch 730: 0.003926278610005929\n",
      "Loss at epoch 731: 0.003910966801140156\n",
      "Loss at epoch 732: 0.0038957555229310707\n",
      "Loss at epoch 733: 0.0038806438307117277\n",
      "Loss at epoch 734: 0.0038656307920020656\n",
      "Loss at epoch 735: 0.003850715485379033\n",
      "Loss at epoch 736: 0.0038358970004702567\n",
      "Loss at epoch 737: 0.0038211744377718918\n",
      "Loss at epoch 738: 0.0038065469082292115\n",
      "Loss at epoch 739: 0.0037920135338755123\n",
      "Loss at epoch 740: 0.0037775734477453423\n",
      "Loss at epoch 741: 0.003763225793194502\n",
      "Loss at epoch 742: 0.003748969723876558\n",
      "Loss at epoch 743: 0.003734804403307303\n",
      "Loss at epoch 744: 0.0037207290045810386\n",
      "Loss at epoch 745: 0.0037067427108017454\n",
      "Loss at epoch 746: 0.0036928447149467136\n",
      "Loss at epoch 747: 0.003679034219574835\n",
      "Loss at epoch 748: 0.0036653104368069593\n",
      "Loss at epoch 749: 0.003651672587783751\n",
      "Loss at epoch 750: 0.003638119902490776\n",
      "Loss at epoch 751: 0.0036246516199592658\n",
      "Loss at epoch 752: 0.0036112669881744634\n",
      "Loss at epoch 753: 0.003597965263905523\n",
      "Loss at epoch 754: 0.0035847457127538163\n",
      "Loss at epoch 755: 0.003571607608647282\n",
      "Loss at epoch 756: 0.003558550233679772\n",
      "Loss at epoch 757: 0.0035455728781999592\n",
      "Loss at epoch 758: 0.003532674840653953\n",
      "Loss at epoch 759: 0.0035198554276065558\n",
      "Loss at epoch 760: 0.0035071139536461933\n",
      "Loss at epoch 761: 0.003494449741151622\n",
      "Loss at epoch 762: 0.0034818621200031043\n",
      "Loss at epoch 763: 0.0034693504276503448\n",
      "Loss at epoch 764: 0.003456914008937578\n",
      "Loss at epoch 765: 0.003444552216158641\n",
      "Loss at epoch 766: 0.003432264408963828\n",
      "Loss at epoch 767: 0.0034200499541520895\n",
      "Loss at epoch 768: 0.003407908225588771\n",
      "Loss at epoch 769: 0.003395838603946619\n",
      "Loss at epoch 770: 0.0033838404767974166\n",
      "Loss at epoch 771: 0.003371913238498991\n",
      "Loss at epoch 772: 0.0033600562901431037\n",
      "Loss at epoch 773: 0.0033482690394562213\n",
      "Loss at epoch 774: 0.0033365509006891875\n",
      "Loss at epoch 775: 0.0033249012943561383\n",
      "Loss at epoch 776: 0.0033133196473496065\n",
      "Loss at epoch 777: 0.003301805392768786\n",
      "Loss at epoch 778: 0.0032903579699263222\n",
      "Loss at epoch 779: 0.0032789768242242378\n",
      "Loss at epoch 780: 0.0032676614071286145\n",
      "Loss at epoch 781: 0.003256411175878322\n",
      "Loss at epoch 782: 0.003245225593603919\n",
      "Loss at epoch 783: 0.003234104129155826\n",
      "Loss at epoch 784: 0.0032230462570599287\n",
      "Loss at epoch 785: 0.003212051457555833\n",
      "Loss at epoch 786: 0.0032011192163648285\n",
      "Loss at epoch 787: 0.003190249024663048\n",
      "Loss at epoch 788: 0.0031794403790134113\n",
      "Loss at epoch 789: 0.00316869278125759\n",
      "Loss at epoch 790: 0.0031580057385022916\n",
      "Loss at epoch 791: 0.003147378763084655\n",
      "Loss at epoch 792: 0.003136811372461557\n",
      "Loss at epoch 793: 0.0031263030890831336\n",
      "Loss at epoch 794: 0.003115853440475613\n",
      "Loss at epoch 795: 0.00310546195891711\n",
      "Loss at epoch 796: 0.003095128181679214\n",
      "Loss at epoch 797: 0.0030848516507920015\n",
      "Loss at epoch 798: 0.0030746319130047794\n",
      "Loss at epoch 799: 0.0030644685198132804\n",
      "Loss at epoch 800: 0.0030543610272262232\n",
      "Loss at epoch 801: 0.003044308995863832\n",
      "Loss at epoch 802: 0.003034311990797619\n",
      "Loss at epoch 803: 0.0030243695815767016\n",
      "Loss at epoch 804: 0.0030144813421499016\n",
      "Loss at epoch 805: 0.0030046468507691987\n",
      "Loss at epoch 806: 0.002994865689998044\n",
      "Loss at epoch 807: 0.00298513744656016\n",
      "Loss at epoch 808: 0.002975461711375188\n",
      "Loss at epoch 809: 0.002965838079509365\n",
      "Loss at epoch 810: 0.002956266150041656\n",
      "Loss at epoch 811: 0.002946745526159727\n",
      "Loss at epoch 812: 0.0029372758149082264\n",
      "Loss at epoch 813: 0.002927856627328525\n",
      "Loss at epoch 814: 0.002918487578321979\n",
      "Loss at epoch 815: 0.0029091682864925235\n",
      "Loss at epoch 816: 0.0028998983744602767\n",
      "Loss at epoch 817: 0.0028906774683496632\n",
      "Loss at epoch 818: 0.002881505198071693\n",
      "Loss at epoch 819: 0.002872381197213\n",
      "Loss at epoch 820: 0.002863305102840343\n",
      "Loss at epoch 821: 0.002854276555640149\n",
      "Loss at epoch 822: 0.002845295199881092\n",
      "Loss at epoch 823: 0.002836360683090079\n",
      "Loss at epoch 824: 0.0028274726565228232\n",
      "Loss at epoch 825: 0.0028186307745013584\n",
      "Loss at epoch 826: 0.0028098346949132764\n",
      "Loss at epoch 827: 0.0028010840788943833\n",
      "Loss at epoch 828: 0.0027923785907186453\n",
      "Loss at epoch 829: 0.0027837178981460157\n",
      "Loss at epoch 830: 0.002775101671872937\n",
      "Loss at epoch 831: 0.0027665295858480686\n",
      "Loss at epoch 832: 0.0027580013172218863\n",
      "Loss at epoch 833: 0.0027495165460056947\n",
      "Loss at epoch 834: 0.0027410749554571162\n",
      "Loss at epoch 835: 0.002732676231757544\n",
      "Loss at epoch 836: 0.0027243200640116247\n",
      "Loss at epoch 837: 0.002716006144356044\n",
      "Loss at epoch 838: 0.0027077341677631756\n",
      "Loss at epoch 839: 0.0026995038320606715\n",
      "Loss at epoch 840: 0.0026913148379791594\n",
      "Loss at epoch 841: 0.0026831668889815514\n",
      "Loss at epoch 842: 0.002675059691332405\n",
      "Loss at epoch 843: 0.0026669929540444263\n",
      "Loss at epoch 844: 0.002658966388807536\n",
      "Loss at epoch 845: 0.0026509797099795863\n",
      "Loss at epoch 846: 0.002643032634624067\n",
      "Loss at epoch 847: 0.0026351248823431967\n",
      "Loss at epoch 848: 0.002627256175361181\n",
      "Loss at epoch 849: 0.002619426238480933\n",
      "Loss at epoch 850: 0.0026116347989572795\n",
      "Loss at epoch 851: 0.002603881586630196\n",
      "Loss at epoch 852: 0.00259616633374136\n",
      "Loss at epoch 853: 0.0025884887749974073\n",
      "Loss at epoch 854: 0.002580848647560438\n",
      "Loss at epoch 855: 0.002573245690877234\n",
      "Loss at epoch 856: 0.002565679646882589\n",
      "Loss at epoch 857: 0.0025581502597307824\n",
      "Loss at epoch 858: 0.002550657275963253\n",
      "Loss at epoch 859: 0.0025432004443551523\n",
      "Loss at epoch 860: 0.0025357795159909368\n",
      "Loss at epoch 861: 0.002528394244100034\n",
      "Loss at epoch 862: 0.002521044384228969\n",
      "Loss at epoch 863: 0.002513729694022377\n",
      "Loss at epoch 864: 0.0025064499333046037\n",
      "Loss at epoch 865: 0.0024992048640791005\n",
      "Loss at epoch 866: 0.002491994250384536\n",
      "Loss at epoch 867: 0.0024848178584243787\n",
      "Loss at epoch 868: 0.002477675456417563\n",
      "Loss at epoch 869: 0.0024705668146365488\n",
      "Loss at epoch 870: 0.0024634917054043885\n",
      "Loss at epoch 871: 0.0024564499029917186\n",
      "Loss at epoch 872: 0.002449441183701248\n",
      "Loss at epoch 873: 0.002442465325760193\n",
      "Loss at epoch 874: 0.002435522109319353\n",
      "Loss at epoch 875: 0.002428611316500274\n",
      "Loss at epoch 876: 0.002421732731244372\n",
      "Loss at epoch 877: 0.002414886139420305\n",
      "Loss at epoch 878: 0.002408071328752622\n",
      "Loss at epoch 879: 0.00240128808872365\n",
      "Loss at epoch 880: 0.0023945362107753916\n",
      "Loss at epoch 881: 0.0023878154879665983\n",
      "Loss at epoch 882: 0.002381125715286635\n",
      "Loss at epoch 883: 0.0023744666893978626\n",
      "Loss at epoch 884: 0.0023678382087095793\n",
      "Loss at epoch 885: 0.002361240073398091\n",
      "Loss at epoch 886: 0.0023546720852662796\n",
      "Loss at epoch 887: 0.002348134047883414\n",
      "Loss at epoch 888: 0.0023416257664203954\n",
      "Loss at epoch 889: 0.002335147047737361\n",
      "Loss at epoch 890: 0.0023286977003057906\n",
      "Loss at epoch 891: 0.002322277534227027\n",
      "Loss at epoch 892: 0.0023158863611848143\n",
      "Loss at epoch 893: 0.0023095239944591547\n",
      "Loss at epoch 894: 0.0023031902488999537\n",
      "Loss at epoch 895: 0.002296884940869677\n",
      "Loss at epoch 896: 0.0022906078883308477\n",
      "Loss at epoch 897: 0.002284358910680742\n",
      "Loss at epoch 898: 0.002278137828908418\n",
      "Loss at epoch 899: 0.0022719444653998685\n",
      "Loss at epoch 900: 0.002265778644091382\n",
      "Loss at epoch 901: 0.0022596401903182384\n",
      "Loss at epoch 902: 0.002253528930900319\n",
      "Loss at epoch 903: 0.00224744469403545\n",
      "Loss at epoch 904: 0.0022413873093987888\n",
      "Loss at epoch 905: 0.002235356607995961\n",
      "Loss at epoch 906: 0.0022293524222662207\n",
      "Loss at epoch 907: 0.0022233745859981235\n",
      "Loss at epoch 908: 0.0022174229343422756\n",
      "Loss at epoch 909: 0.002211497303773103\n",
      "Loss at epoch 910: 0.002205597532138029\n",
      "Loss at epoch 911: 0.002199723458545942\n",
      "Loss at epoch 912: 0.0021938749234498033\n",
      "Loss at epoch 913: 0.002188051768589428\n",
      "Loss at epoch 914: 0.002182253836925151\n",
      "Loss at epoch 915: 0.002176480972803968\n",
      "Loss at epoch 916: 0.002170733021639633\n",
      "Loss at epoch 917: 0.002165009830326482\n",
      "Loss at epoch 918: 0.002159311246705832\n",
      "Loss at epoch 919: 0.0021536371201097623\n",
      "Loss at epoch 920: 0.0021479873008584996\n",
      "Loss at epoch 921: 0.002142361640585389\n",
      "Loss at epoch 922: 0.0021367599920663854\n",
      "Loss at epoch 923: 0.002131182209221473\n",
      "Loss at epoch 924: 0.0021256281471836247\n",
      "Loss at epoch 925: 0.0021200976621830476\n",
      "Loss at epoch 926: 0.002114590611586149\n",
      "Loss at epoch 927: 0.0021091068539225086\n",
      "Loss at epoch 928: 0.0021036462488022265\n",
      "Loss at epoch 929: 0.0020982086568993533\n",
      "Loss at epoch 930: 0.0020927939401145907\n",
      "Loss at epoch 931: 0.0020874019612161883\n",
      "Loss at epoch 932: 0.0020820325842636537\n",
      "Loss at epoch 933: 0.0020766856742301023\n",
      "Loss at epoch 934: 0.0020713610971511837\n",
      "Loss at epoch 935: 0.002066058720238466\n",
      "Loss at epoch 936: 0.0020607784114550286\n",
      "Loss at epoch 937: 0.002055520040178522\n",
      "Loss at epoch 938: 0.002050283476327603\n",
      "Loss at epoch 939: 0.002045068591296556\n",
      "Loss at epoch 940: 0.002039875257072843\n",
      "Loss at epoch 941: 0.002034703346874063\n",
      "Loss at epoch 942: 0.00202955273482584\n",
      "Loss at epoch 943: 0.0020244232958911697\n",
      "Loss at epoch 944: 0.0020193149062870197\n",
      "Loss at epoch 945: 0.0020142274427398317\n",
      "Loss at epoch 946: 0.0020091607834112494\n",
      "Loss at epoch 947: 0.002004114806923273\n",
      "Loss at epoch 948: 0.001999089393162034\n",
      "Loss at epoch 949: 0.001994084422746106\n",
      "Loss at epoch 950: 0.001989099777211307\n",
      "Loss at epoch 951: 0.0019841353390968723\n",
      "Loss at epoch 952: 0.001979190991632125\n",
      "Loss at epoch 953: 0.001974266619159514\n",
      "Loss at epoch 954: 0.001969362106653684\n",
      "Loss at epoch 955: 0.0019644773401555097\n",
      "Loss at epoch 956: 0.001959612206399126\n",
      "Loss at epoch 957: 0.001954766593064809\n",
      "Loss at epoch 958: 0.001949940388640692\n",
      "Loss at epoch 959: 0.0019451334823932043\n",
      "Loss at epoch 960: 0.0019403457645328856\n",
      "Loss at epoch 961: 0.0019355771259056105\n",
      "Loss at epoch 962: 0.001930827458389525\n",
      "Loss at epoch 963: 0.0019260966544000172\n",
      "Loss at epoch 964: 0.001921384607423263\n",
      "Loss at epoch 965: 0.001916691211462779\n",
      "Loss at epoch 966: 0.0019120163615338722\n",
      "Loss at epoch 967: 0.0019073599532291436\n",
      "Loss at epoch 968: 0.0019027218830658887\n",
      "Loss at epoch 969: 0.0018981020481782162\n",
      "Loss at epoch 970: 0.001893500346572929\n",
      "Loss at epoch 971: 0.001888916676904055\n",
      "Loss at epoch 972: 0.0018843509386131114\n",
      "Loss at epoch 973: 0.0018798030318896656\n",
      "Loss at epoch 974: 0.00187527285754338\n",
      "Loss at epoch 975: 0.0018707603172911052\n",
      "Loss at epoch 976: 0.0018662653133029487\n",
      "Loss at epoch 977: 0.0018617877487381506\n",
      "Loss at epoch 978: 0.0018573275271885356\n",
      "Loss at epoch 979: 0.0018528845531516306\n",
      "Loss at epoch 980: 0.0018484587316599296\n",
      "Loss at epoch 981: 0.0018440499685242234\n",
      "Loss at epoch 982: 0.0018396581701574438\n",
      "Loss at epoch 983: 0.0018352832437104863\n",
      "Loss at epoch 984: 0.0018309250969030526\n",
      "Loss at epoch 985: 0.0018265836382627592\n",
      "Loss at epoch 986: 0.0018222587767138649\n",
      "Loss at epoch 987: 0.0018179504222166501\n",
      "Loss at epoch 988: 0.0018136584848241545\n",
      "Loss at epoch 989: 0.001809382875914072\n",
      "Loss at epoch 990: 0.0018051235066939585\n",
      "Loss at epoch 991: 0.0018008802898564918\n",
      "Loss at epoch 992: 0.001796653137807136\n",
      "Loss at epoch 993: 0.0017924419645126513\n",
      "Loss at epoch 994: 0.0017882466835300677\n",
      "Loss at epoch 995: 0.0017840672101237412\n",
      "Loss at epoch 996: 0.0017799034589471533\n",
      "Loss at epoch 997: 0.0017757553465496752\n",
      "Loss at epoch 998: 0.0017716227886766566\n",
      "Loss at epoch 999: 0.0017675057031068147\n",
      "Training time: 0.0974888801574707 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 8.1.0 (20230707.0739)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"697pt\" height=\"394pt\"\n",
       " viewBox=\"0.00 0.00 697.34 394.06\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 390.06)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-390.06 693.34,-390.06 693.34,4 -4,4\"/>\n",
       "<!-- 1563310158608 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1563310158608</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.09\" cy=\"-271.56\" rx=\"37.09\" ry=\"37.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.09\" y=\"-266.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Input 0</text>\n",
       "</g>\n",
       "<!-- 1563327973904 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1563327973904</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"233\" cy=\"-315.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-310.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 0 0</text>\n",
       "</g>\n",
       "<!-- 1563310158608&#45;&gt;1563327973904 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1563310158608&#45;&gt;1563327973904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.77,-293.06C75.39,-297.61 83.81,-301.85 92.18,-304.56 117,-312.6 145.54,-315.84 170.33,-316.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.96,-320.4 180.07,-317.21 170.18,-313.41 169.96,-320.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-333.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 0 0</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-318.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 2.58</text>\n",
       "</g>\n",
       "<!-- 1563310151632 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1563310151632</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"233\" cy=\"-205.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-200.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 0 1</text>\n",
       "</g>\n",
       "<!-- 1563310158608&#45;&gt;1563310151632 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1563310158608&#45;&gt;1563310151632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.5,-270.7C105.64,-269.54 147.82,-266.83 163.43,-260.56 171.58,-257.29 179.52,-252.72 186.94,-247.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"188.43,-250.11 194.4,-241.36 184.27,-244.47 188.43,-250.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-287.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 0 1</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-272.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;4.19</text>\n",
       "</g>\n",
       "<!-- 1563310150160 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>1563310150160</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"233\" cy=\"-95.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"233\" y=\"-90.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 0 2</text>\n",
       "</g>\n",
       "<!-- 1563310158608&#45;&gt;1563310150160 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1563310158608&#45;&gt;1563310150160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M52.36,-237.57C61.33,-220.22 74.57,-200.25 92.18,-188.06 118.84,-169.63 135.61,-189.17 163.43,-172.56 173.99,-166.26 173.31,-160.79 181.43,-151.56 184.35,-148.24 187.38,-144.83 190.44,-141.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.53,-144.19 196.59,-134.4 187.32,-139.52 192.53,-144.19\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-205.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 0 2</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-190.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 0.80</text>\n",
       "</g>\n",
       "<!-- 1563310158224 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1563310158224</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"37.09\" cy=\"-139.56\" rx=\"37.09\" ry=\"37.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.09\" y=\"-134.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Input 1</text>\n",
       "</g>\n",
       "<!-- 1563310158224&#45;&gt;1563327973904 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1563310158224&#45;&gt;1563327973904</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.6,-172.86C62.64,-188.59 75.57,-206.16 92.18,-216.56 119.37,-233.58 137.07,-209.8 163.43,-228.06 176.69,-237.24 171.98,-246.5 181.43,-259.56 184.03,-263.14 186.82,-266.75 189.7,-270.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.47,-272.11 196.57,-277.54 192.84,-267.63 187.47,-272.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-245.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 1 0</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-230.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 2.68</text>\n",
       "</g>\n",
       "<!-- 1563310158224&#45;&gt;1563310151632 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1563310158224&#45;&gt;1563310151632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.29,-134.49C100.08,-132.38 135.06,-132.62 163.43,-144.06 172.9,-147.88 181.91,-153.62 190.1,-160.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.42,-163.25 197.32,-167.03 191.94,-157.9 187.42,-163.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-161.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 1 1</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-146.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;4.10</text>\n",
       "</g>\n",
       "<!-- 1563310158224&#45;&gt;1563310150160 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>1563310158224&#45;&gt;1563310150160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.18,-114.95C73.31,-108.97 82.62,-103.36 92.18,-100.06 116.99,-91.53 145.75,-89.39 170.72,-89.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.43,-93.3 180.53,-90.1 170.64,-86.3 170.43,-93.3\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-118.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 0 1 2</text>\n",
       "<text text-anchor=\"middle\" x=\"127.81\" y=\"-103.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 0.97</text>\n",
       "</g>\n",
       "<!-- 1563310159184 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>1563310159184</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"443.37\" cy=\"-271.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"443.37\" y=\"-266.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 1 0</text>\n",
       "</g>\n",
       "<!-- 1563327973904&#45;&gt;1563310159184 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>1563327973904&#45;&gt;1563310159184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.53,-340.36C306.71,-352.63 343.43,-362.19 373.81,-348.56 386.69,-342.78 398.15,-333.25 407.83,-322.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"410.95,-325.58 414.88,-315.74 405.68,-320.98 410.95,-325.58\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-372.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 0 0</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-357.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;1.10</text>\n",
       "</g>\n",
       "<!-- 1563328573200 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>1563328573200</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"443.37\" cy=\"-51.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"443.37\" y=\"-46.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 1 1</text>\n",
       "</g>\n",
       "<!-- 1563327973904&#45;&gt;1563328573200 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>1563327973904&#45;&gt;1563328573200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.84,-279.9C276.02,-273.52 280.84,-266.63 284.56,-259.56 300.62,-229.03 277.28,-207.54 302.56,-184.06 326.06,-162.24 349.91,-193.96 373.81,-172.56 396.14,-152.57 377.38,-133.84 391.81,-107.56 393.97,-103.62 396.47,-99.73 399.16,-95.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.45,-98.42 405.75,-88.35 396.89,-94.16 402.45,-98.42\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-201.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 0 1</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-186.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 0.02</text>\n",
       "</g>\n",
       "<!-- 1563327950864 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>1563327950864</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"443.37\" cy=\"-161.56\" rx=\"51.56\" ry=\"51.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"443.37\" y=\"-156.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Hidden 1 2</text>\n",
       "</g>\n",
       "<!-- 1563327973904&#45;&gt;1563327950864 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1563327973904&#45;&gt;1563327950864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.8,-314.5C321.99,-313.23 367.1,-310.48 373.81,-304.56 403.43,-278.45 373.95,-252.78 391.81,-217.56 393.88,-213.49 396.32,-209.48 398.99,-205.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.39,-207.92 405.6,-197.82 396.79,-203.71 402.39,-207.92\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-331.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 0 2</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-316.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 1.67</text>\n",
       "</g>\n",
       "<!-- 1563310151632&#45;&gt;1563310159184 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>1563310151632&#45;&gt;1563310159184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.56,-241.43C280.26,-249.01 291.21,-256.07 302.56,-260.56 327.01,-270.25 355.72,-273.72 380.74,-274.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.52,-278.01 390.58,-274.68 380.64,-271.01 380.52,-278.01\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-291.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 1 0</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-276.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;2.22</text>\n",
       "</g>\n",
       "<!-- 1563310151632&#45;&gt;1563328573200 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>1563310151632&#45;&gt;1563328573200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.81,-170.32C276.06,-163.84 280.91,-156.82 284.56,-149.56 302.81,-113.32 271.96,-86.71 302.56,-60.06 314.26,-49.88 349.02,-47.73 380.95,-48.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"380.56,-51.66 390.64,-48.37 380.71,-44.66 380.56,-51.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-78.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 1 1</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-63.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;0.81</text>\n",
       "</g>\n",
       "<!-- 1563310151632&#45;&gt;1563327950864 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>1563310151632&#45;&gt;1563327950864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.56,-166.72C277.77,-157.53 289.72,-148.98 302.56,-144.06 328.15,-134.27 358.11,-136.39 383.72,-141.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"382.86,-145.52 393.4,-144.42 384.48,-138.7 382.86,-145.52\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-161.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 1 2</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-146.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 2.37</text>\n",
       "</g>\n",
       "<!-- 1563310150160&#45;&gt;1563310159184 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>1563310150160&#45;&gt;1563310159184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.62,-131.35C275.83,-137.71 280.71,-144.56 284.56,-151.56 298.99,-177.84 280.23,-196.57 302.56,-216.56 326.46,-237.96 343.82,-216.68 373.81,-228.06 379.72,-230.31 385.66,-233.1 391.45,-236.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"389.57,-239.7 400,-241.59 393.02,-233.61 389.57,-239.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-245.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 2 0</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-230.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 1.86</text>\n",
       "</g>\n",
       "<!-- 1563310150160&#45;&gt;1563328573200 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>1563310150160&#45;&gt;1563328573200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.16,-51.03C270.3,-35.75 284.92,-20.4 302.56,-12.06 331.19,1.47 343.22,-3.88 373.81,-12.06 379.45,-13.57 385.11,-15.67 390.62,-18.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"388.83,-21.62 399.35,-22.85 391.89,-15.33 388.83,-21.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-30.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 2 1</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-15.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;0.54</text>\n",
       "</g>\n",
       "<!-- 1563310150160&#45;&gt;1563327950864 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>1563310150160&#45;&gt;1563327950864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M284.82,-91.64C312.1,-91.34 345.78,-93.91 373.81,-105.06 382.26,-108.42 390.45,-113.23 398.05,-118.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"395.62,-121.95 405.69,-125.22 399.86,-116.38 395.62,-121.95\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-123.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 1 2 2</text>\n",
       "<text text-anchor=\"middle\" x=\"338.18\" y=\"-108.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 0.56</text>\n",
       "</g>\n",
       "<!-- 1563310146768 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>1563310146768</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"645.76\" cy=\"-161.56\" rx=\"43.58\" ry=\"43.58\"/>\n",
       "<text text-anchor=\"middle\" x=\"645.76\" y=\"-156.14\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Output 0</text>\n",
       "</g>\n",
       "<!-- 1563310159184&#45;&gt;1563310146768 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>1563310159184&#45;&gt;1563310146768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M489.1,-247.01C521.33,-229.32 564.74,-205.49 597.53,-187.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"598.83,-190.22 605.91,-182.34 595.46,-184.08 598.83,-190.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-250.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 2 0 0</text>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-235.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 2.67</text>\n",
       "</g>\n",
       "<!-- 1563328573200&#45;&gt;1563310146768 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>1563328573200&#45;&gt;1563310146768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M489.1,-76.11C521.33,-93.8 564.74,-117.64 597.53,-135.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"595.46,-139.04 605.91,-140.79 598.83,-132.9 595.46,-139.04\"/>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-144.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 2 1 0</text>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-129.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: 0.95</text>\n",
       "</g>\n",
       "<!-- 1563327950864&#45;&gt;1563310146768 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>1563327950864&#45;&gt;1563310146768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M495.2,-161.56C524.53,-161.56 561.38,-161.56 591.17,-161.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"590.79,-165.06 600.79,-161.56 590.79,-158.06 590.79,-165.06\"/>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-179.76\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Weight 2 2 0</text>\n",
       "<text text-anchor=\"middle\" x=\"548.56\" y=\"-164.01\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Value: &#45;1.46</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x16bfa0bde90>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a neural network\n",
    "NN = NeuralNetwork(2, [3, 3], 1, \"softplus\", \"CrossEntropy\", 0.01)\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "labels = np.array([[0], [1], [1], [0]])\n",
    "r = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "NN.train(inputs, labels, r, epochs)\n",
    "\n",
    "\n",
    "NN.draw_dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99996061]]\n"
     ]
    }
   ],
   "source": [
    "inputs = np.array([[0, 1]])\n",
    "\n",
    "# Make predictions\n",
    "predictions = NN.predict(inputs)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
