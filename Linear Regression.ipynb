{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (Mean Squared Error) #\n",
    "\n",
    "## Model ##\n",
    "$f_{\\vec{\\omega}\\ ,b}\\left(\\vec{x}\\right)=\\vec{\\omega}\\cdot\\vec{x}+b$\n",
    "## Cost / Loss Functions ##\n",
    "$J(\\vec{\\omega},b) = \\frac{1}{2m} \\sum_{i=1}^{m} \\left[f_{\\vec{\\omega},b}(\\vec{x}^{(i)}) - y^{(i)}\\right]^2$\n",
    "\n",
    "Alternatively,\n",
    "\n",
    "$J(\\vec{\\omega},b) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[f_{\\vec{\\omega},b}(\\vec{x}^{(i)}) - y^{(i)}\\right]^2$\n",
    "\n",
    "## Gradient ##\n",
    "$\\frac{\\partial J\\left(\\vec{\\omega},b\\right)}{\\partial\\omega}=\\frac{1}{m}\\sum_{i=0}^{m-1}\\left[\\left(f_{\\vec{\\omega},b}\\left({\\vec{x}}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right){\\vec{x}}^{\\left(i\\right)}\\right]$\n",
    "\n",
    "$\\frac{\\partial J\\left(\\vec{\\omega},b\\right)}{\\partial b}=\\frac{1}{m}\\sum_{i=0}^{m-1}\\left[f_{\\vec{\\omega},b}\\left({\\vec{x}}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right]$\n",
    "\n",
    "Alternatively,\n",
    "\n",
    "$\\frac{\\partial J\\left(\\vec{\\omega},b\\right)}{\\partial\\omega}=\\frac{2}{m}\\sum_{i=0}^{m-1}\\left[\\left(f_{\\vec{\\omega},b}\\left({\\vec{x}}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right){\\vec{x}}^{\\left(i\\right)}\\right]$\n",
    "\n",
    "$\\frac{\\partial J\\left(\\vec{\\omega},b\\right)}{\\partial b}=\\frac{2}{m}\\sum_{i=0}^{m-1}\\left[f_{\\vec{\\omega},b}\\left({\\vec{x}}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right]$\n",
    "\n",
    "## Gradient Descent ##\n",
    "$\\vec{\\omega}'=\\vec{\\omega}-\\alpha\\frac{\\partial J\\left(\\omega,b\\right)}{\\partial\\omega}$\n",
    "\n",
    "$b'=b-\\alpha\\frac{\\partial J(\\omega,b)}{\\partial b}$\n",
    "\n",
    "Alternative notation,\n",
    "\n",
    "$\\vec{\\omega}:=\\vec{\\omega}-\\alpha\\frac{\\partial J\\left(\\omega,b\\right)}{\\partial\\omega}$\n",
    "\n",
    "$b:= b-\\alpha\\frac{\\partial J(\\omega,b)}{\\partial b}$\n",
    "\n",
    "## Regularized Linear Regression ##\n",
    "$\\frac{\\partial J\\left(\\vec{\\omega},b\\right)}{\\partial\\omega}=\\frac{1}{m}\\sum_{i=0}^{m-1}{\\left[\\left(f_{\\vec{\\omega},b}\\left({\\vec{x}}^{\\left(i\\right)}\\right)-y^{\\left(i\\right)}\\right){\\vec{x}}^{\\left(i\\right)}\\right]+\\frac{\\lambda}{m}\\vec{\\omega}}$\n",
    "\n",
    "$\\frac{\\lambda}{2m}\\sum_{j=0}^{n-1}{[\\vec{\\omega _ j}]}^2$\n",
    "# Misc #\n",
    "Feature Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_footage = [1400, 1600, 1700, 1875, 1100, 1550, 2350, 2450, 1425, 1700]\n",
    "num_bedrooms = [3, 3, 2, 3, 2, 2, 4, 3, 3, 2]\n",
    "num_bathrooms = [2, 2, 2, 2, 1, 2, 3, 3, 2, 2]\n",
    "age_of_house = [5, 6, 10, 5, 15, 5, 1, 4, 6, 8]\n",
    "price = [245000, 312000, 279000, 308000, 199000, 219000, 405000, 324000, 319000, 255000]\n",
    "\n",
    "X = np.array([square_footage,\n",
    "              num_bedrooms,\n",
    "              num_bathrooms,\n",
    "              age_of_house])\n",
    "\n",
    "y = np.array(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (4, 10)\n",
      "The shape of y_train is:  (10,)\n",
      "Number of training examples (m): 4\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_train is:', X.shape)\n",
    "print ('The shape of y_train is: ', y.shape)\n",
    "print ('Number of training examples (m):', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self, X, y, b):\n",
    "        self.input = X\n",
    "        self.y = y\n",
    "        self.weights = np.random.rand(X.shape[1], 1)\n",
    "        self.bias = b\n",
    "\n",
    "    def predict(self, X):\n",
    "        print ('The shape of x_train is:', X.shape)\n",
    "        print ('The shape of y_train is: ', self.weights.shape)\n",
    "        y_hat = X.T @ self.weights + self.bias\n",
    "        return y_hat\n",
    "\n",
    "    def costFunc(self, X, y, w, b):\n",
    "        m = len(X)\n",
    "        cost = (1 / (2*m))*((X @ w + b - y)**2).sum()\n",
    "        return cost\n",
    "\n",
    "    def gradientFunc(self, X, y, w, b):\n",
    "        m = len(X)\n",
    "        gradient = (1/m)*((X @ w + b - y).T @ X).sum(axis=0)\n",
    "        return gradient\n",
    "\n",
    "    def gradientDescentFunc(self, X, y, w, b, lr):\n",
    "        gradDec = w - lr*self.gradientFunc(X, y, w, b)\n",
    "        return gradDec\n",
    "\n",
    "    def train(self, epochs, lr):\n",
    "        costResults = []\n",
    "        for index in range(epochs):\n",
    "            self.weights = self.gradientDescentFunc(self.input, self.y, self.weights, self.bias, lr)\n",
    "\n",
    "\n",
    "# class LinearRegression:\n",
    "\n",
    "#     def __init__(self, X, y, b):\n",
    "#         self.input = X\n",
    "#         self.y = y\n",
    "#         self.weights = np.random.rand(X.shape[0], 1)\n",
    "#         self.bias = b\n",
    "\n",
    "#     def predict(self, X):\n",
    "\n",
    "#         y_hat = X.T @ self.weights + self.bias\n",
    "#         self.weights.size\n",
    "\n",
    "#         return y_hat\n",
    "\n",
    "#     def costFunc(self, X, y, w, b):\n",
    "\n",
    "#         m = len(X)\n",
    "#         cost = (1 / (2*m))*sum(((X.T @ w + b) - y)**2)\n",
    "\n",
    "#         return cost\n",
    "\n",
    "#     def gradientFunc(self, X, y, w, b):\n",
    "\n",
    "#         m = len(X)\n",
    "#         gradient = (1/m)*sum((X.T @ w + b) - y)\n",
    "#         #bias = (1/m)*sum((X @ w + b) - y) @ X\n",
    "\n",
    "#         return gradient\n",
    "\n",
    "#     def gradientDescentFunc(self, X, y, w, b, lr):\n",
    "\n",
    "#         gradDec = w - lr*self.gradientFunc(X, y, w, b)\n",
    "\n",
    "#         return gradDec\n",
    "\n",
    "#     def train(self, epochs, lr):\n",
    "#         costResults = []\n",
    "#         for index in range(epochs):\n",
    "#             self.weights = self.gradientDescentFunc(self.input, self.y, self.weights, self.bias, lr)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.uniform(-1, 1, (4, 1))\n",
    "b = 1\n",
    "linearReg = LinearRegression(X, y, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearReg.train(10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (4, 1)\n",
      "The shape of y_train is:  (10, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\keplarV4\\Downloads\\Github\\ML_Models\\Linear Regression.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m age_of_house \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([square_footage,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m               num_bedrooms,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m               num_bathrooms,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m               age_of_house])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m linearReg\u001b[39m.\u001b[39;49mpredict(x)\n",
      "\u001b[1;32mc:\\Users\\keplarV4\\Downloads\\Github\\ML_Models\\Linear Regression.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThe shape of x_train is:\u001b[39m\u001b[39m'\u001b[39m, X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mThe shape of y_train is: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m y_hat \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/keplarV4/Downloads/Github/ML_Models/Linear%20Regression.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m y_hat\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 10 is different from 4)"
     ]
    }
   ],
   "source": [
    "square_footage = [1400]\n",
    "num_bedrooms = [3]\n",
    "num_bathrooms = [2]\n",
    "age_of_house = [5]\n",
    "\n",
    "x = np.array([square_footage,\n",
    "              num_bedrooms,\n",
    "              num_bathrooms,\n",
    "              age_of_house]).reshape(-1, 1)\n",
    "\n",
    "linearReg.predict(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
